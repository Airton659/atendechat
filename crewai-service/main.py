# crewai-service/main.py - Ponto de entrada principal da API Architect

import os
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import vertexai

# Carregar vari√°veis de ambiente
load_dotenv()

# Inicializar Vertex AI
print(f"üöÄ Inicializando VertexAI...")
try:
    # Usar 'global' para modelos Gemini
    location = os.environ.get("GOOGLE_CLOUD_LOCATION", "global")
    project_id = os.environ.get("GOOGLE_CLOUD_PROJECT")

    if project_id:
        vertexai.init(project=project_id, location=location)
        print(f"‚úÖ VertexAI inicializado! Projeto: {project_id}, Regi√£o: {location}")
    else:
        print("‚ö†Ô∏è GOOGLE_CLOUD_PROJECT n√£o configurado. Usando credenciais padr√£o...")
        vertexai.init(location=location)
        print(f"‚úÖ VertexAI inicializado com credenciais padr√£o! Regi√£o: {location}")
except Exception as e:
    print(f"‚ùå Erro ao inicializar VertexAI: {e}")
    print("‚ö†Ô∏è Continuando sem VertexAI - funcionalidade de gera√ß√£o de agentes estar√° limitada")

# Importar routers
from architect_service import router as architect_router

# Criar aplica√ß√£o FastAPI
app = FastAPI(
    title="Atendechat - Agent Architect API",
    description="API de Gera√ß√£o Autom√°tica de Agentes IA usando Vertex AI (Gemini)",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Configurar CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Incluir routers
app.include_router(architect_router, prefix="/api/v2")

@app.get("/")
def read_root():
    return {
        "service": "Atendechat - Agent Architect API",
        "version": "1.0.0",
        "engine": "Vertex AI (Gemini)",
        "status": "online",
        "features": {
            "architect_agent": True,
            "auto_generate_agents": True,
            "industry_templates": True,
            "vertex_ai": True
        },
        "apis": {
            "v2": "/api/v2/architect",
            "docs": "/docs",
            "redoc": "/redoc"
        }
    }

@app.get("/health")
def health_check():
    """Verifica√ß√£o de sa√∫de"""

    health_status = {
        "status": "healthy",
        "version": "1.0.0",
        "services": {}
    }

    # Verificar VertexAI
    try:
        import vertexai
        health_status["services"]["vertex_ai"] = "available"
    except Exception as e:
        health_status["services"]["vertex_ai"] = f"error: {str(e)}"
        health_status["status"] = "degraded"

    return health_status

@app.get("/version")
def get_version():
    """Informa√ß√µes de vers√£o"""
    return {
        "api_version": "1.0.0",
        "engine": "Vertex AI (Gemini)",
        "model": os.getenv("VERTEX_MODEL", "gemini-2.5-flash-lite"),
        "python_version": os.sys.version,
        "environment": os.environ.get("NODE_ENV", "development"),
        "features": {
            "auto_generate_agents": True,
            "industry_templates": True,
            "business_analysis": True
        }
    }

# Manipulador de erros global
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """Tratamento global de exce√ß√µes"""
    import traceback
    from fastapi.responses import JSONResponse

    print(f"‚ùå Erro n√£o tratado: {exc}")
    traceback.print_exc()

    return JSONResponse(
        status_code=500,
        content={
            "error": "Erro interno do servidor",
            "message": "Ocorreu um erro inesperado. Contate o suporte se o problema persistir.",
            "type": type(exc).__name__,
            "request_path": str(request.url.path)
        }
    )

if __name__ == "__main__":
    import uvicorn

    port = int(os.environ.get("PORT", 8001))
    host = os.environ.get("HOST", "0.0.0.0")

    print(f"üöÄ Iniciando servidor em {host}:{port}")
    print(f"üìö Documenta√ß√£o dispon√≠vel em: http://{host}:{port}/docs")

    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=os.environ.get("NODE_ENV") != "production",
        log_level="info"
    )
